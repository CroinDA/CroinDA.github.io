---
layout: single
title: Data type & Basic Functions
categories:
  - pytorch
tags:
  - 부스트캠프
  - AITech
  - AIBasic
  - PyTorch
author_profile: false
use_math: true
---
## 1. PyTorch의 데이터 타입

### 1.1 PyTorch의 데이터 타입
데이터 타입: Tensor가 저장하는 값의 데이터 유형(정수형 / 실수형)
1. 정수형: 소수 부분이 없는 숫자를 저장하는 데 사용하는 데이터 타입
    - 8비트 부호 없는 정수 : `torch.uint8` (unsigned int8)
        - $2^0$ ~ $2^7$ (1 ~ 128)
    - 8비트 부호 있는 정수 : `torch.int8`
        - $-128$ ~ $127$
    - 16비트 부호 있는 정수 : `torch.int16 or short`
        - $-32,768$ ~ $32,767$
    - <mark style="background: #FFF3A3A6;">32비트 부호 있는 정수</mark> : `torch.int32 or int`
        - $-2,147,483,648$ ~ $2,147,483,647$
        - <mark style="background: #FFF3A3A6;">표준적 정수 크기</mark>
    - 64비트 부호 있는 정수 : `torch.int64 or long`
        - -922경 ~ 922경(63비트 숫자 할당)<br><br>

2. 실수형: <mark style="background: #FFF3A3A6;">신경망 수치계산에 사용 (가장 중요)</mark>
	- (16비트) 고정 소수점 수: 정수부와 소수부로 나누어 표현하는 데이터 형식
		- <u>고정 소수점 수의 문제점</u> : 소수부 각 자리를 4bit씩 따로 저장 ⇒ <mark style="background: #FFF3A3A6;">메모리 감당 불가</mark>
			⇒ 부동 소수점 수로 문제 해결
	- <mark style="background: #FFF3A3A6;">부동 소수점 수</mark>: 숫자를 <u>정규화</u> 하여 <mark style="background: #FFF3A3A6;">가수부와 지수부</mark>로 표현
	    - <u>정규화</u> : $102.5 = 1.025 * 10^2$ → $1.025$(가수부), $10^2$:지수부
		    - <mark style="background: #FFF3A3A6;">32비트</mark> 부동 소수점 수: `torch.float32 or float`
		        - 지수부 8bit + 가수부 23bit (+부호)
		    - <mark style="background: #FFF3A3A6;">64비트</mark> 부동 소수점 수: `torch.float64 or double`
		        - 지수부 11bit + 가수부 52bit (+부호)<br><br>

### 1.2 타입 캐스팅
타입 캐스팅: 임의의 데이터 타입 <mark style="background: #FFF3A3A6;">다른 데이터 타입으로 변환</mark>하는 것
- 딥러닝 모델에서, 매개변수 및 Gradient 저장 시 <mark style="background: #FFF3A3A6;">메모리 부담을 줄여줌</mark><br><br>
`i = torch.tensor([2, 3, 4], dtype = torch.int8)` 가 있을 때, Tensor i를
- 32비트 부동 소수점 수로: `j = i.float()`
- 64비트 부동 소수점 수로: `k = i.double()`

## 2. Tensor의 기초 함수 및 메서드  - 자주 사용하는 표현
### 2.1 Tensor의 요소를 반환하거나 계산하는 함수
- Tensor `I`에 대해,
	- (Tensor의 모든 요소들 중)최소값 반환 ⇒ `torch.min(I)`
	- (Tensor의 모든 요소들 중)최댓값 반환 ⇒ `torch.max(I)`
	- 합 반환 ⇒ `torch.sum(I)`
	- 곱 반환 ⇒ `torch.prod(I)`
	- 평균 반환 ⇒ `torch.mean(I)`<br><br>
	- 표본분산 반환 ⇒ `torch.var(I)`
		- 표본
			- (과학적인 방법을 통해)모집단에서 추출한 <u>일부 데이터</u>의 집합
		- 모집단
			- 관심이 대상이 되는 <u>전체</u> 집단
		- 표본분산
			- 주어진 표본 데이터 집합의 분포 정도
			  (<mark style="background: #FFF3A3A6;">데이터 변동성 판단</mark>의 중요지표)
			- 평균값을 중심으로 얼마나 퍼져 있는가
			- 수식
				- $S^2 = \frac{1}{(n - 1)} \sum_{i=1}^{n} (x_i - \bar{x})^2$
				- $\bar{x}$: 평균
				- $n-1$: 자유도
	- 표본표준편차($=\sqrt{var}$) 반환 ⇒ `torch.std(I)`<br><br>

### 2.2 Tensor의 특성을 확인하는 메서드
Tensor `i`의
- 차원의 수 확인: `i.dim()`
- 크기(모양)확인: `i.size()` or `i.shape()`(attribute 속성)
- 요소의 총 갯수 확인: `i.numel()`(number of elements)

