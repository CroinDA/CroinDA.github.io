---
layout: single
title: "[RecSys / \b딥러닝을 활용한 추천시스템] 딥러닝을 추천시스템에 활용하는 이유 / MLP를 활용한 추천시스템 모델 (NCF, DNN for YouTube Recommendation)"
categories:
  - recsys_basic
tags:
  - 부스트캠프
  - AITech
  - RecSys
  - Deep_Learning
  - MLP
  - NCF
  - YouTube
  - Recommendation
  - readline
author_profile: false
use_math: true
---
## 1. Recommender System with DL
### 추천시스템에서 딥러닝을 활용하는 이유
1. Nonlinear Transformation
	- Deep Neural Network를 통해 <mark style="background: #FFF3A3A6;">데이터의 비선형성(Non-linearity)을 효과적으로 표현</mark>하기 위함
	- 이러한 비선형성을 추천모델에 추가해 줌으로서, <mark style="background: #FFF3A3A6;">복잡한 user-item interaction pattern을 효과적으로 모델링</mark>하여 유저의 선호도를 예측
	- Deep Learning을 통해, <mark style="background: #FFF3A3A6;">추천 모델의 단순함을 DNN을 통해 해결</mark>할 수 있기를 기대
2. Representation Learning
	- DNN은 <mark style="background: #FFF3A3A6;">raw data로부터 feature representation을 학습</mark>하여 사람이 직접 feature를 설계하지 않아도 됨
	- 이를 통해, 다양한 종류의 정보를 추천 시스템에 활용할 수 있음: 텍스트/이미지/오디오 등
3. Sequence Modeling
	- DNN은 sequential modeling task에 성공적으로 적용된 사례가 있음: 자연어 처리 / 음성 신호 처리 등 → 추천시스템의 sequential modeling task에 대해서도 동일한 효과를 보기 위함
	- Next-item prediction / Session-based recommendation 등
4. Flexibility
	- Deep Learning은 다양한 프레임워크 오픈(PyTorch / Tensorflow 등)
	- 추천 시스템 모델링의 flexibility가 높으며, 더 효율적으로 서빙 가능함


## 2. Recommender System with MLP
### MLP(다중 퍼셉트론, Multi-Layer Perceptron)
- Perceptron 여러 개로 이루어진 layer 여러 개를 순차적으로 이어 놓은 feed-forward network
- Input Layer / Hidden Layer / Output Layer로 구성
	- Input Layer(입력층): 데이터를 받아들이는 층
	- Hidden Layer(은닉층): 입력층-출력층 간 중간 처리 계층(1개 이상)
	- Output Layer(출력층): 최종 결과를 출력하는 층<br><br>

### Neural Collaborative Filtering(NCF)
- <mark style="background: #FFF3A3A6;">MF의 한계</mark>를 지적, <mark style="background: #FFF3A3A6;">신경망 구조를 사용</mark>하여 더욱 일반화된 모델 제시
- 아이디어
	- Matrix Factorization의 한계
		- user-item embedding의 선형 조합을 구함 → user-item 간 <mark style="background: #FFF3A3A6;">복잡한 관계를 표현하는 것에 한계</mark>
		- Example in Paper
			![image1](../../images/2024-10-29-aitech-week11-12_6_1/image1.png)
			- 기존의 3명의 사용자에 대한 user-item matrix가 있음
			- user 1,2,3에 대한 벡터를 표현한 공간이 우측 그림의 latent space
			- 여기서, 새롭게 user 4가 등장
			- 문제는 여기 → user 4를 latent space에 표현 시 모순 발생
				- user 4는 user 1과 가장 가까우니, latent space의 파란 점선과 같이 표현됨
				- 하지만, user 4는 user 1 다음으로 user 4와 유사한 user 3와 가까워야 하는데, <mark style="background: #FFF3A3A6;">user 3보다 user 2와 더 가까이 위치</mark>하게됨 → 모순
				- 결론적으로, user 4는 user 1과 가까워도 user 2보다 user 3에 가까울 수 없음
			- 이러한 문제를, latent space의 차원을 높여서 해결 가능 → 비효율적이고 Overfitting 발생 가능성 있음 → 이를 <mark style="background: #FFF3A3A6;">MLP를 통한 비선형성 추가로 해결</mark>하려고 함
	- 이러한 한계점을 보완하기 위해 NCF 모델 제안 → MF에 MLP 결합(GeneralMF + MLP)
- 모델 구조
	- MLP 파트
		![image2](../../images/2024-10-29-aitech-week11-12_6_1/image2.png)
		- Input Layer
			- User, item vector를 One-hot encoding 시킴
			- $v_u$, $v_i$
		- Embedding Layer
			- 앞서 Input Layer에서 변환 one-hot encoding vector ($v_u$, $v_i$)
			- 기존에 존재하던 user, item에 대한 Embedding Matrix ($P$, $Q$)
			- One-hot encoding vector $v_u$, $v_i$와 Embedding Matrix $P$, $Q$ 를 곱해, <mark style="background: #FFF3A3A6;">고정된 크기의 임베딩 벡터</mark>(실수)로 변환
			- 위 과정을 거쳐, Sparse한 One-hot encoding vector 대신 Dense한 Embedding vector로 <mark style="background: #FFF3A3A6;">정보를 압축</mark>하여 표현
			- $P^Tv_u$, $Q^Tv_i$
		- Neural CF Layers
			- Embedding Layer에서 만들어진 두 Latent vector(User, Item)를 concatenation하여 첫 번째 Layer 생성
			- 그 뒤로 Layer를 쌓아 다층 신경망 형성 → 상호작용 학습
			- $\phi^{MLP} = \phi_X(\cdots \phi_2(\phi_1(P^T v_w, Q^T v_i)) \cdots)$
				- $\phi_X$: x번째 neural network
		- Output Layer
			- 활성함수를 통해 예측값을 0~1 범위의 확률로 변환해줌
			- user-item 간 관련도 표현
			- $\hat{y}_{ui} = \phi_{out}\left( \phi_X \left( \cdots \phi_2 \left( \phi_1(P^T v_u, Q^T v_i) \right) \cdots \right) \right), \quad \hat{y}_{ui} \in [0,1]$
	- 최종 결합 모델(GMF + MLP)
		- GMF와 MLP를 앙상블하여 사용
		![image3](../../images/2024-10-29-aitech-week11-12_6_1/image3.png)
		- GMF(General MF): MF를 일반화한 모델
			- Input Layer / Embedding Layer
				- MLP와 Input Layer, Embedding Layer 생성 방식 동일
				- 하지만, GMF와 MLP는 독립적인 임베딩 행렬(파라미터) 사용
					- 같은 user ID / item ID라도 GMF와 MLP에서 뽑아내는 임베딩 벡터 값은 서로 다름
				- 차원이 다를 경우, 추후 concat 불가능 → 차원 불일치에 유의
			- GMF Layer
				- 생성된 MF User Vector와 MF Item Vector를 Element-wise Product로 계산하여 생성
				- $\phi^{GMF} = (p_u^G)^T q_i^G$
		- NeuMF Layer / Output Layer
			- MLP Layer와 GMF Layer를 Concat하여 NeuMF Layer 생성
			- 이렇게 결합된 NeuMF Layer에학습 가능한 가중치 벡터 h를 곱해 스칼라 값으로 변환
			- 변환된 값에 Logistic function(or Probit function)을 통과하여 0~1 범위의 $\hat{y}_{u,i}$ 생성
			- $\hat{y}_{u,i} = \sigma\left(h^T \begin{bmatrix} \phi^{GMF} \\ \phi^{MLP} \end{bmatrix}\right)$
			- $\hat{y}_{u,i}$ → 사용자 $u$와 아이템 $i$가 상호 작용할 확률
	- 모델 성능 결과
		- MovieLens / Pinterest 데이터셋에 대해, NCF 추천 성능이 기존 MF나 MLP 모델보다 높음
			![image4](../../images/2024-10-29-aitech-week11-12_6_1/image4.png)
	- 해당 모델 및 논문이 갖는 의의
		- 성능의 드라마틱한 향상보다는, MLP를 기존 MF에 처음 추가한 논문이라는 점에서 의미
		- RecSys 모델에도 DNN이 효과가 있다! 는 것을 보여준 사례<br><br>

### Youtube Recommendation
- Deep Learning 기반 추천 시스템을 실제 유튜브 서비스에 적용한 논문
- 실제 YouTube가 적용한 모델의 논문<br><br>
- 유튜브 추천 시스템의 핵심 도전과제
	1. Scale
		- 매우 다량의 유저와 아이템 정보(수백만 개의 동영상, 수억 명의 사용자 정보). 하지만 컴퓨팅 파워는 제한적 → 효율적 서빙 및 이에 특화된 추천 알고리즘 필요(고도로 전문화된 분산 학습 알고리즘 필요) 
	2. Freshness
		- 매초마다 수많은 동영상이 업로드됨 → 새로운 콘텐츠를 빠르게 반영 + 기존 콘텐츠와의 균형(실시간으로 이를 적절히 조합해야 함)
	3. Noise
		- 데이터의 Sparsity와 다양한 외부 요인들로 인해 유저 만족도에 관련한 실제 지표를 얻기 매우 어려움 → Noise를 다량 포함한 Implicit Feedback 필요, 낮은 품질의 메타 데이터를 잘 활용해야 함
- 전반적인 구조: 2단계 추천 시스템
	![image5](../../images/2024-10-29-aitech-week11-12_6_1/image5.png)
	1. Candidate Generation
		- 목적: "High Recall" → 수백만 개의 동영상에서 수백 개의 관련성 높은 후보 선별
		- 주어진 사용자에 대해 <mark style="background: #FFF3A3A6;">Top N 추천아이템</mark> 생성
	2. Ranking
		- 목적: 선별된 후보들 중 상대적 중요도를 구분하여 최종 순위 결정
		- 유저 / 비디오 feature를 좀 더 풍부하게 사용
		- score를 구해 최종 추천 리스트 제공
- Candidate Generation
	![image6](../../images/2024-10-29-aitech-week11-12_6_1/image6.png)
	- 문제 정의(핵심 아이디어): "Extreme Multiclass Classification" → 추천을 <mark style="background: #FFF3A3A6;">Extreme Multiclass Classification로 재정의</mark> 하는 것
		- 특정 시간 t에 유저 U가 C라는 context를 갖고 있을 때, <mark style="background: #FFF3A3A6;">비디오(i) 각각을 볼 확률</mark> 계산
			- 비디오가 수백만개 → "Extreme"
			- 결국 마지막에 Softmax 함수를 사용하는 분류 문제 → "결국 시청하는 영상은 하나"
		- $P(w_t = i \mid U, C) = \frac{e^{v_i^u}}{\sum_{j \in V} e^{v_j^u}}$
			- $w_t=i$: 시간 $t$에 동영상 $i$를 시청
			- $U$, $C$: 사용자 정보, context 정보
			- $u$: 사용자와 context의 고차원 임베딩
			- $v_j$: 각 후보 동영상의 임베딩
	- 모델 구조
		- 다양한 Feature vector
			- Watch Vector 및 Search Vector → <mark style="background: #FFF3A3A6;">사용자의 과거 행동을 요약</mark>한 두 가지 주요 벡터
				- 과거 시청 이력 & 검색 이력 각각 임베딩
					- 과거 시청 이력
						- 각 동영상 i는 사전 학습된 임베딩 $v_i$ 갖고 있음
						- 사용자가 마지막으로 시청한 $K$개의 시청 이력 활용
						- $K$: 시스템 성능 및 메모리 제약을 고려해 수십-수백개 수준으로 설정
							- 최근 영상에 가중치 부여 가능
							- 장르/카테고리가 편향되지 않도록 균등하게 샘플링
						- 단순 평균치 계산
					- 과거 검색 이력
						- 사용자가 입력한 검색 쿼리들의 임베딩 집계한 벡터
						- 각 쿼리들 토큰화 → 각 토큰들에 대한 임베딩 조회 → 임베딩 전체 평균
						- 핵심 의미만 반영, 지나치게 일반적이거나 불용어 제거
						- 토큰 중요도 가중치 적용 가능(TF-IDF, Attention 기반 가중치)
				- 마지막 검색어에 너무 큰 가중치를 두지 않도록 평균
			- Dempgraphic & Geographic features
				- 인구통계(gender 등) 정보 / 지리적 정보 → feature로 포함
			- <mark style="background: #FFF3A3A6;">'Example Age'</mark> features
				- 앞서 언급한 'Freshness' 문제 해결을 위한 핵심 기법
					- 문제: 모델이 과거 데이터 위주로 편향되어 학습되는 문제
					- 해결: 학습 시 <mark style="background: #FFF3A3A6;">각 예시에 대한 age</mark>을 feature로 추가 → Bootstraping 현상 방지 및 Freshness 제고
		- User Vector 생성 → Concatenate feature vector
			- 위와 같은 다양한 feature vector를 한 번에 concatenate
			- ReLU 활성함수를 사용하는 MLP Layer 통과 → User vector 생성
		- Training: Softmax Classification
			- “이 사용자가 다음에 볼 동영상은 무엇인가?“를 맞히는 문제에 대해 학습
				- "Extreme Multiclass Classification" 문제
			- 학습 과정
				1. User vector - 모든 video vector에 대해 내적
				2. 위 계산을 통해, 모든 동영상에 대한 내적 결과(=점수)들 전체를 softmax 함수에 넣어 확률 분포 생성 → <mark style="background: #FFF3A3A6;">각 동영상이 선택될 확률</mark> 계산
				3. 실제로 사용자가 본 동영상이 정답이 되도록 파라미터 업데이트(확률값 최대화)
		- Serving: Top-N 후보 추천
			- 실제 서비스: 수백만 개 동영상 중 빠르게 상위 N개 추천해야 됨
			- 유저(user vector)를 input으로 하여 상위 N개 비디오 추출
			- Serving 과정
				1. 학습된 네트워크에 user의 최신 행동을 입력하여 user vector 생성
				2. 이렇게 생성된 user vector를 Nearest Neighbor index에 넣음
					- Nearest Neighbor index: 모든 video vector ↔ user vector 간 유사도를 빠르게 계산하는 구조
				3. user vector와 가장 유사한(=내적값이 가장 큰 순서대로) 동영상 Top-N개를 근사적으로 빠르게 찾아냄
				4. YouTube를 키면 우리가 흔히 아는 "알고리즘을 탄 동영상"들이 쭉 추천되어 나타나게 됨
- Ranking
	- 문제 정의
		- 앞선 Candidate Generation 단계에서 생성된 비디오 후보들을 input으로 넣어 <mark style="background: #FFF3A3A6;">최종 추천될 비디오의 순위</mark>를 매기는 문제
		- CG 단계를 통해 추려진 Top-N개의 비디오에 관한 벡터들만을 입력받음
		- DL 구조보다는, 도메인 전문가의 역량이 좌우하는 파트
			- 서비스에 알맞는 Feature 선택이 중요
			- 많은 Feature Selection, Feature Engineering 필요
	- 모델 구조
		- Concat Feature: CG 단계에서 전달받은 수백 개의 후보 영상에 대한 feature concat
			- 논문에서 나타난 Embedding 외에도 실제 수십~수백개의 feature 함께 사용
			![image7](../../images/2024-10-29-aitech-week11-12_6_1/image7.png)
			1. 행동 이력 기반 Embedding Feature
				- Watched Video Embedding
					- 사용자가 최근 시청한 동영상들의 ID를 임베딩 테이블에서 벡터로 변환
					- 여러 개의 임베딩 벡터를 평균(pooling)하여 하나의 대표 벡터로 만듦
					- 사용자의 취향과 최근 관심사를 요약
			2. 개별 속성 Embedding Feature
				- Language Embedding
					- 범주형 속성(사용자 언어, 영상 언어 등)을 각각 임베딩 테이블에서 벡터로 변환
					- 언어 선호 및 언어별 추천 최적화에 활용
				- Impression Video ID Embedding
					- 현재 추천 후보 영상의 ID를 임베딩 벡터로 변환
					- 각 후보 영상의 고유 특성 반영
			3. 연속성 Feature 및 변환 Feature
				- 시간 관련 Feature: 'time since last watch'
					- 원본 값 → 누적분포(CDF) 등으로 정규화(normalize)
					- 정규화된 값($\tilde{x}$), 제곱($\tilde{x}^2$), 제곱근($\sqrt{\tilde{x}}$) 등 다양한 변환값을 함께 입력
				- 노출/빈도 관련 Feature: '# previous impressions'
					- 해당 영상의 누적 노출 횟수
					- 마찬가지로 정규화 및 다양한 수학적 변환값 함께 입력
			4. Context 및 환경 feature: 사용자 환경 정보
				- 디바이스 종류, 지역, 세션 정보 등의 정보
				- 범주형 값은 임베딩, 연속형 값은 정규화 후 입력 
			5. 상호작용 및 관계 feature: 사용자-영상 상호 작용 Feature
				- 과거에 해당 채널/카테고리에서 시청한 횟수, 마지막 시청 시점 등
				- 정규화 또는 임베딩 후 입력
		- Feature 입력 방식
			- 범주형 feature
				- 각 고유값(예: 영상 ID, 언어, 카테고리 등)마다 <mark style="background: #FFF3A3A6;">임베딩 테이블</mark>에서 <mark style="background: #FFF3A3A6;">고정 차원의 벡터를 조회</mark>
				- 값의 종류가 많을수록(수십만~수백만) 임베딩 차원도 로그 스케일로 증가
				- 여러 값이 있는 경우(예: 최근 시청 영상 K개)는 각 임베딩을 평균(pooling)해서 하나의 벡터로 만듦
			- 연속형 feature
				- <mark style="background: #FFF3A3A6;">정규화 필수</mark>
					- 누적분포함수(CDF), min-max, z-score 등을 통해 0~1 구간에 매핑
				- 추가로, 정규화된 값의 제곱, 제곱근 등 다양한 변환값도 함께 입력(비선형 효과 학습을 위해)
				- 신경망이 비선형 효과를 쉽게 학습하도록 feature space를 확장
		- 실제 입력 벡터 구성
			- 모든 임베딩 벡터와 정규화된 연속형 feature들을 한 줄로 concat, ReLU의 입력으로 사용
	- Concat된 벡터의 ReLU 통과
		- 여러 임베딩(영상, 언어, 사용자 등)과 정규화된 연속형 feature(시간, 노출 횟수 등)를 하나의 긴 벡터로 concat
		- 이 벡터가 MLP, 즉 여러 개의 Dense Layer(완전연결층)를 순차적으로 통과
		- 여러 층을 거칠 수록, 점점 더 복잡하고 추상적인 특징을 뽑아낼 수 있음
		- 마지막 Dense Layer의 출력이 <mark style="background: #FFF3A3A6;">각 후보 영상에 대한 최종 feature vector</mark>
	- Training
		- 목표: 각 후보 영상에 대해 "사용자가 실제로 시청/클릭할 확률" or "예상 시청 시간" 예측하기
		- 과정
			- MLP 출력단
				- 마지막 MLP Layer의 출력값을 Logistic Regression을 통해 값 변환
				- “이 사용자가 이 영상을 클릭(시청)할 확률” 또는 “이 영상을 얼마나 오래 볼지(예상 시청 시간)”
			- Loss Function
				- 클릭 예측: 이진 크로스엔트로피(positive/negative example)
					- 기본적으로 해당 논문은, 주어진 user-item context에 대해, 해당 아이템이 노출되었을 때 클릭할 확률을 구하는 문제
				- 시청 시간 예측: <mark style="background: #FFF3A3A6;">Weighted Logistic Regression</mark> → 시청 시간으로 가중치 부여
					- Loss function을 단순 클릭여부 뿐 아니라, 시청 시간을 가중치로 한 값을 반영해주기 위한 조치
					- 단순 binary가 아닌, weighted cross-entropy loss를 활용하여 비디오 시청 시간으로 가중치 → 낚시성, 광고성 콘텐츠를 업로드하는 <mark style="background: #FFF3A3A6;">abusing 현상 감소</mark>(Loss 계산에 거의 반영 X)
			- 학습 데이터
				- MLP를 통과한 데이터와 실제 데이터를 비교
					- 실제 클릭/시청했으면 정답은 1, 보지 않았다면 정답은 0
					- 예측값과 실제값 간 Loss 계산
				- 가중치 업데이트
					- 오차가 작아지도록 신경망의 모든 가중치(임베딩, MLP의 가중치 등)를 조금씩 조정
					- 수십~수백만 번 반복, “어떤 상황에서 어떤 영상을 추천해야 할지” 점점 더 잘 배우게 됨
	- Serving: 실시간 추천 과정
		- 실시간 입력 받기
			- 사용자가 유튜브 앱을 켜고, 홈 화면에 들어옴
			- 서버가 이 사용자의 최신 정보(시청 기록, 언어, 기기, 최근 클릭/노출 등)를 실시간으로 모읍니다.
		- Embedding Vector 생성, MLP 통과
			- 앞선 과정들과 동일하게, 모든 벡터 concat해서 embedding하고, MLP 통과해서 각 후보 영상 별 예상 점수(시청 확률, 예상 시청 시간) 계산
		- 점수로 정렬, Top-N 추천
			- <mark style="background: #FFF3A3A6;">점수가 가장 높은 순서대로</mark> 후보 영상 정렬
			- 상위 N개(예: 20~50개)를 뽑아 추천 리스트 생성
			- 이 리스트가 사용자의 유튜브 홈 화면에 바로 표시
- 요약 및 의의
	- 처음으로 DL을 이용한 추천 시스템의 이론과 Serving의 문제까지 담아냈다는 점에서 의미
	- DL 기반 2단계 추천을 처음으로 제안
		- Candidate Generation: 유저에게 적합한 수백 개의 후보 아이템 추려냄
		- Ranking: 더 Rich한 feature를 활용하여 CG 단계에서 추린 수백 개의 후보 아이템 중 최종 추천 아이템 10-20개 제공
	- Candidate Generation
		- 기존 CF 아이디어 기반, 다양한 feature를 사용해 추천 성능 향상
			- 유저 feature: watch/query history, demographic, geographic 등
			- 아이템 feature: Example Age
	- Ranking
		- 과거에는 선형/트리 기반 모델 위주 활용→ 해당 논문에서 제안한 모델이 <mark style="background: #FFF3A3A6;">기존 선형/트리 모델들 보다 더 뛰어난 성능</mark>을 보여줌
		- Rich Feature: CG단계에서 사용한 feature + 이외에 더 많은 feature를 사용하여 Ranking 단계 수행
		- 단순 CTR(Click to Rate) 예측이 아닌 "Expected Watch Time" 예측 → 실제로 "유저가 해당 영상을 클릭할까?" 라는 수준을 넘어서, "얼마나 해당 영상을 오래 시청할 것인가?"라는 지표를 예측 목표로 삼았다는 점에서 의의<br><br>
