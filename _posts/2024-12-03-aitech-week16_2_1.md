---
layout: single
title: Zero-shot / One-shot / Few-shot Learning
categories:
  - generative_ai
tags:
  - 부스트캠프
  - AITech
  - LLM
  - Pretrained-model
  - GenAI
  - GenerativeAI
  - Zero-shot
  - One-shot
  - Few-shot
  - ML
author_profile: false
use_math: true
---
## 0. N-shot Learning
- 실제 현실에서는, 확보 가능한 데이터에 대해 다음과 같은 어려움이 있음
	- 모델 학습 시 충분한 양의 데이터 및 라벨을 확보하기 어려움
	- 또한, 데이터의 중요성이 부각됨에 따라 데이터의 값어치도 올라가고 있고 라벨링 비용 또한 매우 높을 때가 있음
- 이에 따라, N-shot learning 개념을 도입하여 아래와 같은 문제에 대해 보완하고자 하였음
	- (앞서 언급한)데이터 수집 및 라벨링의 한계
		- 각 산업군 현장에 따라 데이터 자체가 적은 현장도 있음 → 대량의 데이터 확보에 한계
	- 실제 문제의 다양성
		- <mark style="background: #FFF3A3A6;">새로운 클래스 / 상황이 끊임없이 등장하는 환경</mark>에서는 매번 대량의 데이터를 수집 및 학습하는 것이 비효율
	- 일반화와 적응력
		- 제한된 예시만으로 새로운 클래스를 빠르게 인식하여 모델 성능의 일반화를 도모함
		- 이에, <mark style="background: #FFF3A3A6;">기존에 학습되지 않은 상황에서도 빠르게 적응할 수 있는 AI</mark>를 만들기 위해 → N-shot learning으로 시도<br><br>
- 요약 → <mark style="background: #FFF3A3A6;">데이터 라벨링 비용 절감</mark> / <mark style="background: #FFF3A3A6;">모델의 빠른 적응</mark> / <mark style="background: #FFF3A3A6;">실제 적용성 향상</mark>을 목표로 등장한 N-shot learning<br><br>

## 1. Zero-shot Learning
- 모델이 <mark style="background: #FFF3A3A6;">학습 과정 중에 한 번도 본 적 없는 새로운 클래스</mark>를 인식하거나 분류할 수 있도록 하는 ML 기법
	- 클래스 간 관계 / 속성 / 의미 정보(Semantic Embedding, 텍스트 설명 등)를 활용, 본 적 없는 클래스 추론
	- ex) 동물 분류 모델이 얼룩말 이미지를 학습하지 않았더라도, 얼룩말이 '줄무늬 있는 말'이라는 설명을 통해 인식할 수 있음
- 학습 / 추론의 관점
	- 추론: 새롭게 접한 클래스도 해당 클래스에 대한 설명 / 속성 등 보조 정보만으로 예측하는 방법
	- 학습: 새로운 클래스 데이터 없이 예측 가능한 추론 방법 + 이러한 <mark style="background: #FFF3A3A6;">일반화 능력을 갖출 수</mark> 있도록 <mark style="background: #FFF3A3A6;">모델을 설계하고 학습</mark>시키는 방법론
- <mark style="background: #FFF3A3A6;">라벨링 데이터가 부족</mark>하거나 <mark style="background: #FFF3A3A6;">새로운 클래스 등장이 잦은 환경</mark>에 적합
- 하지만, <mark style="background: #FFF3A3A6;">클래스 간 의미 정보가 명확하지 않거나 설명이 부족</mark>한 경우 성능이 저하될 수 있음<br><br>

## 2. One-shot Learning
- One-shot learning이 등장한 기술적 배경
	- 단순히 Few-shot / Zero-shot Learning처럼 데이터 수량 구분을 위한 것이 아님
	- 실제로, <mark style="background: #FFF3A3A6;">인간의 학습 방식을 모방</mark>하려는 구체적인 기술적 도전과제에서 출발
	- 인간은 사물을 한 번만 봐도 다른 맥락에서 쉽게 인식하고 구별(실제 어린이는 6세까지 세상의 10,000~30,000개의 물체 범주를 학습)
	- 이렇게 하나만 보고 빠른 일반화를 이루어내는 인간의 일반화 능력을 기계로 구현하는 것을 핵심 도전과제로서 One-shot learning이 등장
- One-shot Learning?
	- 각 클래스(범주)마다 단 하나의 예시(샘플)만 보고 새로운 객체나 패턴을 인식하거나 분류할 수 있도록 설계된 학습 방법
	- 각 클래스 별로 단 한개의 예시만으로 분류 및 인식 가능 → <mark style="background: #FFF3A3A6;">매우 빠른 일반화 능력</mark> 보유
- One-shot learning을 통한 기존 ML의 문제점 및 해결 방안 제시
	- 기존 딥러닝의 한계(대량의 데이터 필요) + 실제 데이터 부족 문제 해결의 필요성 대두
	- 인간의 학습 방식에서 영감받은 "하나만 봐도 기억하고 구별"하는 일반화 능력
	- "새로운 클래스가 단일 예시와 얼마나 비슷한가?"를 판단
- 핵심 메커니즘 ⇒ "유사도 기반 분류 메커니즘"
	- Metric Learning을 통한 거리 학습
	- <mark style="background: #FFF3A3A6;">두 이미지 간 유사도 측정을 정확히</mark>
	- 과정
		1. 새로운 클래스의 단일 예시가 Support Set으로 제공
		2. 쿼리 이미지(새로운 데이터) 입력
		3. 사전학습된 임베딩 함수를 통해 두 데이터(새 클래스의 단일 데이터 / 쿼리 이미지) 모두 특징 벡터로 변환
			- 거리 함수 학습: 같은 클래스는 가깝게 / 다른 클래스는 멀게 배치되도록
		4. 거리 및 유사도 계산
			- 유사도 계산: 새로운 쿼리 ↔ Support Set(각 클래스 당 하나의 예시만을 포함하는 데이터셋)
		5. 가장 높은 유사도를 가진 클래스로 분류<br><br>

## 3. 학습 메커니즘 비교: Zero-shot Learning vs One-shot Learning
- One-shot Learning
	- 직접 입력 데이터와 Support Set을 비교
	- 유사도 기준: Metric Learning(직접적 특징 비교)
	- ex) 이 새로운 고양이 이미지는 Support Set의 스핑크스 고양이 사진 1장과 얼마나 시각적으로 유사한가?
- Zero-shot Learning
	- Support Set이 없기 때문에, 각 클래스의 텍스트 설명/속성 등의 정보 및 입력되는 데이터를 동일한 임베딩 공간에 매핑하여 비교
	- 즉, <mark style="background: #FFF3A3A6;">교차 임베딩 공간에 매핑</mark>하여 서로 다른 모달의 데이터를 비교
	- 유사도 기준: Semantic Embedding(의미적 관계를 동일 임베딩 공간에서 비교)
	- ex) 이 새로운 동물 이미지는, ‘줄무늬가 있는 말과 같은 동물’이라는 텍스트 설명과 의미적으로 얼마나 일치하는가? → 모델이 이 '새로운 동물 이미지'가 얼룩말임을 추측해냄<br><br>

## 4. Few-shot Learning
- N-shot Learning / Zero-shot 및 One-shot을 포함하는 범주
- Few-shot Learning(FSL) 등장배경
	- 극소수의 예시만으로 새로운 클래스 및 태스크를 빠르게 학습 및 일반화할 수 있도록 설계
	- One-shot Learning과 마찬가지로 인간의 능력을 모방하는 것에 초점, 여기에 <mark style="background: #FFF3A3A6;">Meta Learning</mark> 개념을 도입하여, "학습하는 법을 학습할 수 있도록" 하여 빠르게 적응하도록 하는 패러다임 제안
	- 일반적으로 클래스 별 2~10개의 예시 데이터를 포함한 Support Set 구성
	- FSL의 핵심은, <mark style="background: #FFF3A3A6;">학습과정 자체를 테스트 환경과 동일한 형태로 구성</mark>함에 있음
- Few-shot Learning 핵심 메커니즘
	1. Pre-training
		- 앞선 Zero-shot / One-shot과 동일
	2. Episodic Training
		- 실제 FSL <mark style="background: #FFF3A3A6;">테스트 환경과 훈련 환경을 일치(N-way K-shot)</mark>시켜 수천~수만 개의 에피소드 반복 학습 → '일반화의 극대화' 도모
			- N-way K-shot: N개의 클래스에 대해 각 K개의 예시만 제공
			- 각 에피소드: Support Set + Query Set 
				- Support set: 각 클래스당 K개의 레이블된 예시
				- Query set: 분류·검증 대상 샘플
				- Episode = N-way K-shot 태스크 단위
	3. Meta-Testing(적응 및 추론 프로세스)
		- Episodic Learning을 통해 얻은 메타 지식 → 새로운 N-way K-shot 태스크에 빠르게 적응하고 Query 샘플을 분류하는 과정
		- 적응-추론의 2단계 프로세스
			1. 적응 단계: Support Set 활용, 새로운 태스크에 특화된 지식 획득
			2. 추론 단계: 적응된 모델로 Query 샘플 분류
		- 모델별 적응 메커니즘
		- 목표 → Support set만 보고 Query 샘플의 클래스를 정확히 예측
			1. Metric-based 방법들의 적응/추론
				-  Prototype Networks
					- 적응 단계: Support Set에서 각 클래스의 프로토타입(평균 임베딩) 계산
						- $c_k = \frac{1}{|S_k|} \sum_{(x_i, y_i) \in S_k} f_\phi(x_i)$
					- 추론 단계: Query 샘플을 각 프로토타입과의 거리로 분류 → 가장 가까운 프로토타입의 클래스로 분류
						- $p(y = k \mid x) = \frac{\exp\left(-\left|f_\phi(x) - c_k\right|^2\right)} {\sum_j \exp\left(-\left|f_\phi(x) - c_j\right|^2\right)}$
				- Matching Networks
					- 적응 단계
						- Support Set의 모든 샘플을 임베딩하여 메모리로 활용
						- Attention 메커니즘으로 Support-Query 간 관계성 학습
					- 추론 단계
						- Query와 각 Support 샘플 간 attention weight 계산
							- $\hat{y} = \sum_{i=1}^{k} a(\hat{x}, x_i) y_i$
						- Attention 가중 평균으로 최종 예측 수행
			2. Optimization-based 방법들의 적응/추론
				- MAML(Model-Agnostic Meta-Learning)
					- 적응 단계
						- 메타 학습된 초기 파라미터 $\theta$에서 시작
						- Support Set을 이용하여, 몇 번의 gradient step 수행
						- 일반적으로 1-5회의 적응 단계 진행
					- 추론 단계
						- 적응된 파라미터 $\theta$로 Query 샘플 분류
				- ALFA(Adaptive Learning of hyperparameters for Fast Adaption)
					- 적응 단계
						- 태스크별로 학습률과 정규화 계수를 동적 생성
						- 메타 네트워크가 현재 학습 상태에 따라 최적 하이퍼파라미터 결정
					- 추론 단계
						- 적응된 태스크별 파라미터로 Query 분류 수행
			3. Memory 방법
				- 외부 메모리에 Support 정보를 저장
		- 적응 과정의 핵심 메커니즘
			- Task-specific Adaptation
				- 태스크별 맞춤화: 각 새로운 태스크의 특성에 맞게 모델 조정
				- Support Set 활용: 소수의 예시만으로도 태스크 고유 패턴 포착
				- 과적합 방지: 제한된 파라미터만 업데이트하여 일반화 능력 유지
			- Fast Adaptation
				- 소수 스텝: 보통 1-5번의 업데이트로 적응 완료
				- 효율성: 전체 재학습 대비 극소 연산량으로 높은 성능 달성
				- 메타 지식 활용: 에피소딕 학습으로 획득한 사전 지식 재활용
			- Transductive vs. Inductive 추론
				- Inductive: Support Set만 활용하여 적응
				- Transductive: Support와 Query Set 모두 활용하여 성능 향상
