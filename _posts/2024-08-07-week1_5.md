---
layout: single
title: Basic Operations on Tensors
categories:
  - pytorch
tags:
  - 부스트캠프
  - AITech
  - AIBasic
  - PyTorch
author_profile: false
---
## 1. Tensor의 모양변경 2

### 1.1 cat() 함수를 활용한 Tensor들 간의 연결

- cat() vs stack()
    - stack : 새로운 차원을 생성해서 Tensor 결합
    - cat : **기존의 차원을 유지하면서** Tensor 연결
- cat() 매서드
    - b = torch.tensor([[0, 1], [2, 3]]) / c = torch.tensor([[4, 5]])
        1. dim = 0 기준으로 연결
            
            : d = torch.**cat((b, c))**
            
            (tuple로 묶어 입력)
            
        2. dim = 1 기준으로 연결
            
            : d = torch.cat((b, c), **1**) → Error(dim=1 차원의 숫자 안맞음)
            
            ⇒ d = torch.cat((b, c.reshape(2,1),1)
            

### 1.2 expand() 메서드를 활용한 Tensor 크기 확장

- Tensor의 **차원의 크기 1**일때 해당 차원의 크기 확장

- f = torch.tensor([[1, 2, 3]])
    1. f의 크기를 (1, 3)에서 (4, 3)으로 확장
        
        ⇒ g = f.expand(4, 3)
        
        ![[images/2024-08-07-week1_5/image1.png]]
        

### 1.3 repeat()메서드를 활용한 Tensor 크기 확장

- h = torch.tensor([[1, 2], [3, 4]])
    1. h를 dim = 0축 방향으로 2번 반복, dim = 1 축 방향으로 3번 반복
        
        ⇒ i = h.repeat(2, 3)
        
        ![[images/2024-08-07-week1_5/image2.png]]
        

## 2. Tensor의 기초 연산

### 2.1 Tensor의 산술연산 - 함수 vs in-place

1. 더하기 연산
    - 크기가 같은 Tensor : 각 요소들을 더한 값으로 출력
        
        a = torch.tensor([[1, 2], [3, 4]]), b = torch.tensor([[1, 3], [5, 7]])
        
        - 일반 연산 → torch.**add(a,b)**
        - in-place 연산 → a.**add_(b)** ( id() 메서드로 고유 식별자 확인 → 메모리 주소 같은지 확인 가능)
    - 크기가 다른 Tensor : **Broadcating** 발생 후 연산
        
        c = torch.tensor([[1, 2], [4, 5]]), d = torch.tensor([[1, 3]])
        
        - d = torch.tensor ([[1, 3], [1, 3]])으로 Broadcasting 발생
        - 코드는 동일 (torch.add(c, d))
    
2. 빼기 연산
    - 크기가 같은 Tensor : 각 요소들을 더한 값으로 출력
        
        e = torch.tensor([[2, 3], [4, 5]]), f = torch.tensor([[2, 4], [6, 8]])
        
        - 일반 연산(f에서 e를 빼기) → torch.**sub(f, e)**
        - in-place 연산 → a.**sub_(b)** ( id() 메서드로 고유 식별자 확인 → 메모리 주소 같은지 확인 가능)
    - 크기가 다른 Tensor : **Broadcasting** 발생 후 연산
        
        g = torch.tensor([[2, 3], [5, 6]]), h = torch.tensor([[1], [4]])
        
        - h = torch.tensor ([[1, 1], [4, 4]])으로 Broadcasting 발생
        - 코드는 동일 (torch.add(g, h))

1. 스칼라곱 연산
    - i = 2, j = torch.tensor([[1, 2], [3, 4])
        
        → torch.**mul(i, j)**
        
2. 요소별 곱하기 연산
    - k = torch.tensor([[1, 2], [1, 3]]), I = torch.tensor([[2, 3], [1, 4])
        - 일반 연산 → torch.**mul(k, I)**
        - in-place 연산 → k.**mul_(I)**
    - 크기가 다른 Tensor ⇒ Broadcating 발생 후 연산

1. 요소별 나누기 연산
    - o = torch.tensor([[18, 9], [10, 4]]), p = torch.tensor([[6, 3], [5, 2])
        - 일반 연산 → torch.**div(o, p)**
        - in-place 연산 → o.**div_(p)**
    - 크기가 다른 Tensor ⇒ Broadcating 발생 후 연산

1. 스칼라 거듭제곱(근) 연산
    - s = torch.tensor([[1, 2], [3, 4]]), n = scalar
        - Tensor s의 각 요소의 n제곱 → torch.**pow(s, n)**
        - Tensor s의 각 요소의 n제곱근(1/n승) → torch.**pow(s, 1/n)**
2. 요소별 거듭제곱 연산
    - t  = torch.tensor([[5, 4], [3, 2]), u = torch.tensor([[1, 2], [3, 4])
        - 일반 연산 → torch.**pow(t, u)**
        - in-place 연산 → t.**pow_(u)**

### 2.2 Tensor의 비교연산

- v = torch.tensor([1, 3, 5, 7]), w = torch.tensor([2, 3, 5, 7])
    1. 대응요소들이 같은지 비교
        
        → torch.**eq(v, w)**
        
    2. 대응요소들이 다른지 비교
        
        → torch.**ne(v, w)**
        
    3. v의 각 요소들이 w의 각 요소들보다 **큰지** 비교 (greater than)
        
        → torch.**gt(v, w)**
        
    4. v의 각 요소들이 w의 각 요소들보다 **크거나 같은**지 비교 (greater equal)
        
        → torch.**ge(v, w)**
        
    5. v의 각 요소들이 w의 각 요소들보다 **작은지** 비교 (less than)
        
        → torch.**lt(v, w)**
        
    6. v의 각 요소들이 w의 각 요소들보다 작**거나 같은**지 비교 (less equal)
        
        → torch.**le(v, w)**
        

### 2.3 Tensor의 논리연산

- 전자 회로를 구성하는 가장 기본적인 논리 게이트 : 논리곱(AND), 논리합(OR), 배타적 논리합(XOR)
    1. 논리곱 (AND)
        
        → 입력된 신호가 **모두 참일때, 출력이 참**이 되는 연산
        
        → torch.**logical_and(x, y)**
        
        - 참 + 참 → 참
        - 참 + 거짓 → 거짓
        - 거짓 + 참 → 거짓
        - 거짓 + 거짓 → 거짓
    2. 논리합 (OR)
        
        → 입력된 신호가 둘 중 **하나라도 참일때, 출력이 참**이 되는 연산
        
        → torch.logical_or(x, y)
        
        - 참 + 참 → 참
        - 참 + 거짓 → 참
        - 거짓 + 참 → 참
        - 거짓 + 거짓 → 거짓
    3. 배타적 논리합 (XOR)
        
        → 입력된 신호가 둘 중 **하나만 참일때, 출력이 참**이 되는 연산
        
        → torch.logical_xor(x, y)