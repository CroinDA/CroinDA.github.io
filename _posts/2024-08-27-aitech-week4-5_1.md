---
layout: single
title: 최신 Recsys 동향 및 통계학 기본
categories:
  - ml_recsys
tags:
  - 부스트캠프
  - AITech
  - AIBasic
  - recsys
  - 통계
  - 확률분포
  - 중심극한정리
  - MLE
  - Likelihood
author_profile: false
use_math: true
---
## 1. 최신 Recsys 동향
### 1.1 추천시스템 최근동향
- Recsys 발전방향
    1. Shallow Model
	    - 행렬 분해를 Recsys에 활용(잘 모델링 하려면, 어떻게 행렬을 분해해야 할까)
		    ![image1](../../images/2024-08-27-aitech-week4-5_1/image1.png)
	        - 좌측 : user matrix
	        - 상단 : item matrix
	        - 가운데(원소) : user matrix * item matrix
    2. Deep Model
	    - Neural Network를 활용한 모델링(AutoRec)
		    ![image2](../../images/2024-08-27-aitech-week4-5_1/image2.png)
	        - Rating Matrix : i번째 item을 소비하는 User들 / binary로 사용여부 표기
	        - Rating Matrix를 input, 해당 input을 최대한 그대로 복원 
		        → 관측되지 않은 Data에 대해 추론 가능
    3. Large-scale Generative Models
	    1. Text based(Multitasking)
            ![image3](images/2024-08-27-aitech-week4-5_1/image3.png)
            - P5 ⇒ Text 입력 시 번역/감정 분류/요약 등 <mark style="background: #FFF3A3A6;">여러가지 task를 하나로 수행 가능</mark>한 통합 모델
	    2. Multi-Modal based(text + img)
	        ![image4](../../images/2024-08-27-aitech-week4-5_1/image4.png)
	    3. Diffusion based(CV, L-DiffRec)
		    - Noise를 어떻게 가하는지 추론 ⇒ 반대로 빼주면 목적 달성(복원)
		      (베네시안 AutoEncoder)
		    ![image5](../../images/2024-08-27-aitech-week4-5_1/image5.png)
		    - Objective of Recommender Systems
			    - Historical Interactions - Diffusion 모델을 RecSys에 활용 / 일부의 관측값만 주어짐
			    - Predicted future interactions - Historical Interaction이 RecSys를 통과하면서 그럴듯한 Rating Matrix로 변환
        4. 결국 Recsys의 발전 방향?
		    - <mark style="background: #FFF3A3A6;">“Explainability”</mark>
		        - 왜 이것을 추천?
		        - item 간 관계?
		        - 유저의 호불호 설명
	        - <mark style="background: #FFF3A3A6;">“Debiasing”</mark> and <mark style="background: #FFF3A3A6;">“Casuality”</mark>
		        - Debiasing : 애초에 Recsys는 편향된 모델(특정 유저 대상이기에, 너무나도 당연) 
			        → bias: 진짜 좋아하는 것, 유명해서 띄워줬으나 금방 닫는 것 등등을 All 포함
		        - Casuality → 인과성을 고려하여 우수한 예측을 만들어내는 것<br><br>

## 2. ML for RecSys
 ⇒ 이번 Part의 핵심은 <mark style="background: #FFF3A3A6;">RecSys을 이해하는 데 필요한 ML 개념 완성</mark>
### 2.1 Overview
![image6](../../images/2024-08-27-aitech-week4-5_1/image6.png)
- Recsys 최근 동향
	- Generative Model
	- Data Valuation
	- Casual Inference
	- Casual Graph Discovery
- Recsys의 심도있는 이해를 위한 중요 개념(수학, 통계, ML)
    - 각종 확률분포(Normal, Beta, Uniform 등)
    - 통계학의 개념 및 활용분야
    - 생성모델 및 이를 학습하기 위한 추론 기법(Variational Inference, MCMC 등)
    - Data Valuation 및 Casuality 개념 이해 및 Python 구현<br><br>

## 3. 통계학 기본
### 3.1 Random Variable
- "확률변수" - 각 사건(확률실험)에 대하여, 발생할 수 있는 결과를 해당 사건을 대표하는 <mark style="background: #FFF3A3A6;">실수</mark>값으로 바꾸어 표현한 것
	- input: 사건의 집합 S
	- output: real-value 하나의 값
- Ex)Random Variable X: 두 개의 주사위를 던져서 나오는 값의 합
	- Sample Space: $S = (i, j) : 1 \leq i, j \leq 6$
	- Random Variable: **$X(i, j) = i + j$** (사건: 주사위 양면의 합)
	  (좌변: function, 우변: real-value)<br><br>

### 3.2 (Probability) Distribution
- Random Variable : 이산적이기도 하고, 연속적이기도 함
- Definition by ​Discrete(연속확률분포는 수학적으로 더 깊게 들어가야 함) 
	- 고려해야 하는 가짓수가 한정적일 때
	- 각 확률 변수 X에 대해, Sample Space에서 X에 대한 빈도수(확률값)를 불러와 summation
	- 모든 X에 대해 y를 정의하여, 공식/표/그래프 등으로 나타낸 것이 확률분포(Probability distribution)
- 이산 확률 분포(Discrete probability distribution)란?
	-  $0 \leq p(y) \leq 1$, $\sum_y P(y)=1$ 을 만족하는 확률 분포<br><br>

### 3.3 Binomial & Bernoulli Distribution
- Random Variable의 실행결과가 <mark style="background: #FFF3A3A6;">이진값(0, 1)</mark>으로 구성
- n회 시행하였을 때, 결과가 둘 중 하나가 나오는 확률 분포
	- 1번 시행 시 0이 나올 확률 - p
	- 1번 시행 시 1이 나올 확률 - 1-p
- 실행환경 : i.i.d
	- Identical Independent - 동일한 환경에서 독립적으로
- Binomial vs Bernoulli
    - Bernoulli : 1 trials
    - Binomial : n trial (연속, 독립)
- 관심사 : (일반적으로) 성공횟수, 앞면 나온 횟수
- Formula
	- $p(y) = \binom{n}{y} p^y q^{n-y} \quad \text{where } y = 0, 1, \dots, n \text{ and } 0 \leq p \leq 1$
	- Discrete PDF - probability mass function
	![image7](../../images/2024-08-27-aitech-week4-5_1/image7.png)<br><br>

### 3.4 Uniform Distribution
- 각 실험별 확률이 균등한 분포
	![image8](../../images/2024-08-27-aitech-week4-5_1/image8.png)
	- $f(y) =\begin{cases} \frac{1}{\theta_2 - \theta_1}, & \theta_1 \leq y \leq \theta_2 \\ 0, & \text{elsewhere} \end{cases}$
	- 엄밀히 정의하기 위해서는, density 개념도 짚고 넘어가야 함
		- 위 식의 density : $\frac{1}{\theta_2 - \theta_1}$
		- Discrete - probability mass function<br><br>

### 3.5 Normal probability distribution
- 정규분포(=가우시안분포, 노멀분포)
	![image9](../../images/2024-08-27-aitech-week4-5_1/image9.png)
    - $f(y) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(y-\mu)^2}{2\sigma^2}}, \quad -\infty < y < \infty$
    - $\mu = 0$, $\sigma^2 = 1$

### 3.6 Beta probability distribution
- 확률변수 $X$가 <mark style="background: #FFF3A3A6;">0과 1사이의 값</mark>($0\leq y \leq 1$)을 갖는 연속확률분포
	- 0~1의 값을 갖는 모델링 구성에 많이 이용
	- 특정한 확률값을 모델링할 때 활용
    ![image10](../../images/2024-08-27-aitech-week4-5_1/image10.png)

### 3.7 Central Limit Theorem (중심극한정리) - "$Y$가 아닌 $\bar{Y}$의 분포에 대한 정리"
- $Y$에서 n개씩 추출된 표본 $\bar{Y}$ : 아래 두 가지 조건을 갖추었다면, $\bar{Y}$는 <mark style="background: #FFF3A3A6;">표준정규분포를 따른다</mark>고 볼 수 있음.
  (skewness가 사라짐)
	1. 추출하는 표본의 크기 n이 무수히 클 때
	2. 동일한 환경에서 독립적으로 추출(I.I.d)할 때
    - $Y$ : 표본의 크기 n이 커질 수록, 평균 $\mu$ / 분산 $\sigma^2$를 갖는 확률분포
      ⇒ $\bar{Y}$ : 평균 $\mu$, 분산은 $\sigma^2 / n$ 인 확률분포로 수렴
    - 정규 분포에서 평균 $\mu$와 분산 $\sigma^2$를 가진 표본이 추출되었다면:
        - $\bar{Y}$는 정규 분포를 따르며, 기댓값 $E[\bar{Y}] = \mu$이고, 분산 $V[\bar{Y}] = \frac{\sigma^2}{n}$이다.
    - **어떤 분포**에서 추출된 표본이라도 **표본 크기가 충분히 크다면**:
        - $\bar{Y}$는 근사적으로 정규 분포를 따르며, 기댓값 $E[\bar{Y}] = \mu$이고, 분산 $V[\bar{Y}] = \frac{\sigma^2}{n}$이다.
	        ![image11](../../images/2024-08-27-aitech-week4-5_1/image11.png)<br><br>

### 3.8 Likelihood & Prior
 - Likelihood(경향성)
	 - n개의 데이터가 수집 되었을 때, 이 n개의 데이터가 나오게 될 <mark style="background: #FFF3A3A6;">경향성</mark> → $L(y_1, ...,y_n|\theta)$
		 - $L(y_1, ...,y_n|\theta)$ = $f(y_1|\theta) * ... * f(y_n|\theta)$ (각 sample에서 나오게 될 경향성의 곱)
			- $\theta$ : MLE(Maximum Likelihood Parameter)
			- 최적화 시키고자 하는 parameter(데이터가 나올 경향성을 가장 잘 설명)
				- 많은 PDF에서 알 수 없는 $\mu$와 $\sigma$에 대해, 데이터가 나올 Likelihood를 가장 잘 설명할 수 있는 $\theta$
				- 즉, n개의 Data를 가장 잘 설명할 수 있는 model parameter 최대화
			- 실제 데이터갯수가 무한대로 뻗어간다면, MLE가 ground truth 값으로 근사
		 - 경향성은 확률과는 살짝 다른 개념
- Prior(믿음)
	- 앞선 Likelihood는 $\mu$, $\sigma$값을 최적화 시키기 위한 것이었다면, prior는 최적화를 위한 $\mu$, $\sigma$값을 넣어서 값을 확인해보는 과정
		- 쉽게 말하면, 확률분포에 관해 사전에 알고 있는 정보를 넣어주는 것(어떤 분포를 따를 것이다, 어떤 범위 안에 있을 것이다 등) → 이를 likelihood와 결합해 주기 위함
	- $\mu$, $\sigma$가 어느 값의 범위에 있을 것 같다는 예상을 prior가 제공함 → 값을 넣어봄
		- $p(\theta | x^{(1)}, \dots, x^{(m)}) = \frac{p(x^{(1)}, \dots, x^{(m)} | \theta) p(\theta)}{p(x^{(1)}, \dots, x^{(m)})}$
			- 분자 - Likelihood(주어진 데이터를 가장 잘 생성할 법한 $\theta$ 추정) * prior
			- 분모 - 데이터
			- 결과 - Bayesian Rule에 따른 posterior 값
			  (데이터를 given으로 줄 때, $\theta$에 대한 믿음(prior)도 결합되어 MLE($\theta$) 추정)
		- 정확한 posterior를 알 수 없는 경우가 많음 → 이를 위한 Bayesian Inference / M.C.M.C와 같은 방법론 등장