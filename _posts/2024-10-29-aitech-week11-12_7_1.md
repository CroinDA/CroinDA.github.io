---
layout: single
title: "[RecSys / 딥러닝을 활용한 추천시스템] GNN을 활용한 추천시스템 모델: NGCF, LightGCN"
categories:
  - recsys_basic
tags:
  - 부스트캠프
  - AITech
  - RecSys
  - Deep_Learning
  - GNN
  - NGCF
  - LightGCN
author_profile: false
use_math: true
---
## 1. Graph Neural Network
### Graph
- Node(꼭짓점)들과 그들을 잇는 edge(변)들을 모아 구성한 자료구조
- 표현법: 일반적으로 $G=(V, E)$ 로 정의(Vertice(Node), Edge(Arc))
- ex) G = ({A, B, C, D}, ({A, B}, {A, C}, {A, D}, {C, D}))           
	 ![image1](../../images/2024-10-29-aitech-week11-12_7_1/image1.png)<br><br>

### Graph를 사용하는 이유
1. 추상적인 개념을 다루기 적합
	- 복잡한 문제를 ==간단히 단순화== / 다른 관점으로 표현 가능
	- "유저가 아이템을 소비한다"고 하면
		- 유저/아이템: Node
		- 소비: Edge
2. Euclidean 뿐 아니라, Non-Euclidean Space의 표현 및 학습 가능
	- Euclidean Space
		- ==유한한 실수로 표현== 가능한 공간
		- 우리가 흔히 다루는 데이터(이미지, 텍스트, 정형 데이터 등)는 격자 데이터로 표현 가능
	- Non-Euclidean Space
		- ==노드와 엣지==로 이루어진 데이터 → 전통적인 유클리드 공간(예: 2차원 평면, 3차원 공간)처럼 ==격자나 연속적인 좌표계에 자연스럽게 배치할 수 없음==
		- SNS 데이터, 분자 데이터 등<br><br>

### 그래프 신경망(GNN, Graph Neural Network)
- 그래프 데이터에 적용 가능한 신경망
- 이웃 노드 간 정보 이용 → ==특정 노드를 잘 표현할 수 있는 feature(벡터)==를 잘 찾아내는 것
	- 방법: 그래프 / 피처 데이터를 인접 행렬로 변환 → "Naive Approach"        
		![image2](../../images/2024-10-29-aitech-week11-12_7_1/image2.png)<br><br>

### GCN(Graph Convolution Network)
- "Naive Approach"의 한계
	- 노드 갯수에 따른 연산량이 ==기하급수적으로 증가==(인접행렬을 만든 후, 그대로 입력값으로 이용)
	- 또한, 노드의 순서가 변경되면 의미가 달라짐
- 해결책 → Convolution 효과 만들어줌
	1. 이웃 노드의 정보만을 참고하여 정보 집계 
	2. 가중치 공유
	3. 다수의 층을 쌓아 깊은 관계 추출 가능
- GCN의 Convolution 효과
	- 기존 CNN의 convolution 개념 → ==Non-Euclidean 공간으로 확장==시킨 것
	- 이를 통해, 연산량을 줄임과 함께 Deep Network로 간접적 관계 특징까지 추출 가능        
	![image3](../../images/2024-10-29-aitech-week11-12_7_1/image3.png)
	1. Local connectivity
	2. Shared weights
	3. Multi-Layer<br><br>

## 2. NGCF(Neural Graph Collaborative Filtering)
GCN이 추천시스템 문제를 해결하기에 성능이 우수한 모델임을 처음으로 밝혀낸 모델       
- User-Item 상호작용을 GNN으로 임베딩하는 과정에서 인코딩하는 접근법을 제시한 논문<br><br>

### NGCF 등장 배경
학습 가능한 CF 모델의 두 가지 Key Point
1. User-Item 임베딩
2. 상호작용 모델링<br><br>
기존 CF 모델의 문제 → 이러한 User-Item 간 상호작용을 ==임베딩 단계에서 접근할 수가 없음==
- Collaborative Signal에는 임베딩 과정을 인코딩할 수 없음
	- Collaborative Signal: RecSys에서 비슷한 사용자가 비슷한 아이템에 대해 보이는 행동패턴 또는 상호작용 정보 전체
- Latent factor 추출을 "사용자-아이템 간 interaction function"에만 의존
- 결론적으로, sub-optimal한 임베딩만 사용하게 되는 결과 → ==부정확한 추천의 원인==이 될 수 있음<br><br>

### NCGF의 기본 아이디어
High-order Connectivity
- 1차 연결 (Direct Connection):
	- 사용자 A → 영화 X (직접 시청)
- 2차 연결 (Indirect Connection):
	- 사용자 A → 영화 X ← 사용자 B "A와 B는 같은 영화 X를 봤으니 비슷한 취향임"
- 3차 연결 (Higher-order Connection):
	- 사용자 A → 영화 X ← 사용자 B → 영화 Y "B가 영화 Y를 봤으니, A도 영화 Y를 좋아할 가능성이 높음"

NGCF의 개선된 알고리즘
- NGCF는 이러한 Higher-order Connectivity를 임베딩을 만들 때부터 활용하고자 함
	- User-Item 상호작용을 임베딩 단계부터 학습될 수 있도록 접근
	- User, Item 갯수가 많아질 수록 모든 상호작용을 표현해 주기엔 한계 → GNN을 통해 High-order Connectivity 임베딩
- High-order Connectivity 예시: $u_1$(user 1)에 대한 High-order Connectivity 표현          
	![image4](../../images/2024-10-29-aitech-week11-12_7_1/image4.png)         
	- item 4, item 5는 user 2를 매개로 user 1에 추천될 확률이 높아짐
	- user 1, user 2는 item 2를 매개로 상호작용
	- item 4는 user 2, user 3를 매개로 2번 전달되니 추천될 확률이 높아짐<br><br>

### NGCF 전체구조 분석
- Model Architecture                 
	![image5](../../images/2024-10-29-aitech-week11-12_7_1/image5.png)
	1. Embedding Layer(임베딩 레이어)
		- 유저 노드(왼), 아이템 노드(오) 초기 임베딩 제공
		- 기존 방법과 동일하게 모든 유저/아이템에 대해 ID 기반 임베딩 레이어를 구성
		- 해당 논문에서는 64차원의 임베딩 레이어 구성하여 실험
	2. Embedding Propagation Layer(임베딩 전파 레이어)
		- 기존 방법 vs Collaborative Filtering
			- 기존(MF, Neural CF 등): Embedding이 곧바로 interaction function에 입력
			- Collaborative Filtering: Embedding을 GNN상에 전파시켜 다시 Embedding을 정의해줌 → ==Collaborative Signal을 명시적으로 주입==해주기 위한 과정
		- 단계별 절차
			1. Message Construction
				- User-item간 정보를 연결해주기 위한 message 정의
				- 정보 전파를 위해 생성한 임베딩 $m_{u \leftarrow i}$ / $f(\centerdot)$: 메시지 인코딩 함수
					- $m_{u \leftarrow i} = f(e_i, e_u, p_{ui})$
					- $m_{u \leftarrow i} = \frac{1}{\sqrt{\vert N_u \vert \vert N_i \vert}}(W_1e_i + W_2(e_i \odot e_u))$
						- $W_1e_i$: 변환된 아이템 정보 / $W_2(e_i \odot e_u)$: 아이템 정보 + 사용자 정보
						- $p_{ui} = \frac{1}{\sqrt{\vert N_u \vert \vert N_i \vert}}$, 
				- $W_1, W_2$ 의 역할
					- 특징 추출/강화 (Feature Transformation)
						- $W_1$
							- 이웃 임베딩에서 정보 추출, 필요한 방향으로 변형
							- 그 '이웃 임베딩'을 필요에 따라 특정 관점에서 바라볼 수 있도록 변환
						- $W_2$: $e_1, e_2$ 간 element-wise product(=item 1, 2 간 유사도) 결과값에 곱해주어 새로운 방식(조합/해석/강조 등)으로 재구성
							- 이전과 다른 특징 벡터로 변환해주는 과정
							- 이를 통해, ==기존 임베딩에서 잡히지 않는 관계까지 포착==할 수 있게 해줌
					- 가중치 조절/학습
						- 두 가지 입력(이웃 정보, 유사도 신호)을 각각 "얼마만큼 반영"할지 신경망이 학습
						- 학습 데이터에 따라, 어떤 상황에서는 $W_1$이, 어떤 상황에서는 $W_2$가 더 중요할 수 있음
			2. Message Aggregation
				- 임의의 user에 대해, 이웃으로부터 전파된 메시지를 합쳐셔 user의 representation을 다시 표현해내는 과정
					- 1-hop 전파를 통한 임베딩 완료 과정
				- $e_u^{(1)} = LeakyReLU(m_{u \leftarrow u} + \sum_{i \in \mathcal{N}_u}m_{u \leftarrow i})$
					- $e_u{(1)}$: user u의 표현(첫번째 전파 레이어의 결과)
					- $LeakyReLU$: 활성함수
						- 양수는 그대로(좋아하는 것 반영)
						- 음수는 0.01 곱함(싫어하는 것도 약하게 고려)
					- $m_{u \leftarrow u}$: 원본 특징 정보(=$W_1e_u$)
			3. High-order Propagation
				- 앞서 1-2번 과정을 통해 얻은 표현(First-order Propagation)에 더하여, Embedding Propagation Layer를 더 쌓음 → 고차원 정보 획득
				- 이를 통해, 유저는 자신의 l-hop으로부터 전파된 메시지를 받을 수 있게 됨
				- l-hop 전파를 통한 유저 u의 representation $e_u^{(l)}$
					- $e_u^{(l)} = LeakyReLU(m_{u \leftarrow u}^{(l)} + \sum_{i \in \mathcal{N}_u}m_{u \leftarrow i}^{(l)})$
				- l-hop으로부터 오는 메시지 $m_{u \leftarrow i}^{(l)}$ , (l-1 hop으로부터 메시지에서 기억함)
					- $m_{u \leftarrow i}^{(l)} = p_{ui}(W_1^{(l)}e_i^{(l-1)} + W_2^{(l)}(e_i^{(l-1)} \odot e_u^{(l-1)}))$
					- $m_{u \leftarrow u}^{(l)} = W_1^{(l)}e_u^{(l-1)}$
	3. Prediction Layer(유저-아이템 선호도 예측 레이어)
		- Embedding Propagation Layer의 각 층에서 만들어진 모든 정보를 합침
			- 최종 사용자 임베딩 = (0층 임베딩 $\Vert$ 1층 임베딩 $\Vert$ 2층 임베딩 $\Vert$ 3층 임베딩)
			- 최종 아이템 임베딩 = (0층 임베딩 $\Vert$ 1층 임베딩 $\Vert$ 2층 임베딩 $\Vert$ 3층 임베딩)
			- 층별 정보
				- 0층: 기본 선호도 정보
				- 1층: 직접적 유사성 정보
				- 2~3층: 간접적 협업 신호
				- 모두 합쳐서 → 다양한 관점을 종합적으로 판단
		- 적절한 L값(논문에서 언급한 실험 분석 내용)
			- 얕은 레이어 vs 깊은 레이어
				- L이 너무 작으면(레이어가 얕으면)
					- high-order connectivity를 충분히 반영하지 못함 → Collaborative Signal을 충분히 활용 못함
				- L이 너무 크면(레이어가 깊어지면)
					- 오히려 '노이즈'와 '과적합'이 증가하여 성능이 떨어질 수 있음
		- 최종 예측 점수
			- $\hat{y}_{NGCF}(u,i) = e_u^{\ast\, \top}e_i^{\ast}$<br><br>

### 실험 결과 요약
- Embedding Propagation Layer가 많아질 수록 모델의 추천 성능은 향상됨
- 다만, 앞서 언급하였듯 Embedding Propagation Layer가 너무 많아지면 과적합 및 노이즈 증가
- 실험 결과, NGCF-3,4(3,4개 정도의 레이어를 쌓았을 때)에서 최적의 성능(Yelp2018 Dataset)        
	![image6](../../images/2024-10-29-aitech-week11-12_7_1/image6.png)
- MF vs NGCF
	- MF에 비해 높은 recall값을 나타냄(세 개의 데이터셋으로 실험한 결과)                     
		![image7](../../images/2024-10-29-aitech-week11-12_7_1/image7.png)
	- MF에 비해 빠른 수렴 양상을 보임
		- Embedding Propagation Layer를 통한 representation power 강화
		- MF에 비해 유저-아이템이 Embedding space에서 더 명확히 구분
			- 레이어가 많아질수록 명확                      
		![image8](../../images/2024-10-29-aitech-week11-12_7_1/image8.png)<br><br>

## 3. LightGCN
### LightGCN 핵심 아이디어
LightGCN은 ==기존 GCN 기반의 추천모델을 가볍게== 만드는 데에 초점을 두고 연구        
- 기존의 그래프 신경망(GCN)들은 노드 분류(node classification) 작업을 위해 설계 → 각 노드가 풍부한 의미적 특성(예: 논문의 제목, 초록 등)을 가지고 있음
- But, 추천시스템에서는 상황이 다름
	- 사용자와 아이템은 단순히 ID로만 표현
	- 구체적인 의미적 정보 없음
	- 복잡한 변환과 비선형 활성화 함수는 오히려 방해
- 이러한 이유들로 인해, GCN을 추천시스템에 적용해서 취할 수 있는 장점을 선별하여 적용한 모델이 LightGCN
	- 기존 최고 성능 모델인 NGCF
	- NGCF에 대해, 철저한 ablation study를 수행하여 꼭 필요한 부분만 남기고자 함
	- NGCF의 주요 구성 요소
		- Feature Transformation: $W_1, W_2$ (Weight Matrix)
		- Nonlinear Activation: $\sigma$ Function
		- Neighborhood Aggregation: NGCF의 핵심 메커니즘
	- NGCF의 구성 요소들을 제거해본 실험 결과
		- '-f': Feature Transformation 제거
		- '-n': Nonlinear Activation 제거
		- '-fn': 둘 다 제거                
		![image9](../../images/2024-10-29-aitech-week11-12_7_1/image9.png)                  
         
		![image10](../../images/2024-10-29-aitech-week11-12_7_1/image10.png)         
		- Feature transformation을 제거하면 성능 향상
		- Nonlinear activation을 제거해도 성능 유지 혹은 개선
		- 둘 다 제거한 "NGCF-fn" → 원본 NGCF보다 9.57% 향상된 성능을 보임
	- 위 실험 결과 고찰
		- 복잡한 신경망 연산들이 Collaborative Filtering에서는 오히려 훈련을 어렵게 만들고 성능을 저하시킨다는 것을 알수 있었음
		- 이러한 사실을 기반으로, "가장 본질적인 것만 남겨보자"는 철학과 함께 LightGCN 설계가 시작됨<br><br>

### LightGCN의 핵심 아이디어
Light Graph Convolution
- 핵심 특징
	- 선형 집합만 사용: 복잡한 변환 없음
	- 정규화된 합: 임베딩 스케일 안정화
	- 자기 연결 없음: Layer Combination으로 대체<br><br>

### LightGCN 전체 구조 분석
구성 컴포넌트 개요
- LGC(Light Graph Convolution)
	- 목적: 이웃 노드의 정보를 선형적으로 집합
	- 특징: 복잡한 변환 없이 단순 평균화
	- 개선점: Self-connection 제거
- Layer Combination
	- 목적: 사용자-아이템 선호도 예측
	- 특징: 내적을 통한 간단한 점수 계산
	- 개선점: 복잡한 예측 레이어 불필요
- Model Prediction
	- 목적: 사용자-아이템 선호도 예측
	- 특징: 내적을 통한 간단한 점수 계산
	- 개선점: 복잡한 예측 레이어 불필요           
	![image11](../../images/2024-10-29-aitech-week11-12_7_1/image11.png)<br><br>

모델 아키텍처 세부
1. Light Graph Convolution
	- 간소화한 가중치 합만 사용
	- Feature transformation, nonlinear activation 제외
	- 수식
		- $e_u^{(k+1)} = \sum_{i \in N_u}\frac{1}{\sqrt{\vert N_u \vert \vert N_i \vert}}e_i^{(k)}$
		- $e_i^{(k+1)} = \sum_{u \in N_i}\frac{1}{\sqrt{\vert N_u \vert \vert N_i \vert}}e_u^{(k)}$
	- Standard GCN의 디자인을 따름
		- 스케일 안정성: 임베딩 크기가 폭발적으로 증가하는 것 방지
		- 공정한 기여: 인기 있는 아이템/활동적인 사용자의 과도한 영향 방지
		- 수렴 보장: 훈련 과정에서 안정적인 그래디언트 흐름
2. Layer Combination
	- 왜 레이어를 결합해야 할까? → 각 레이어는 서로 다른 의미를 담고 있음
	- 레이어별 의미:
		- Layer 0: 원본 사용자/아이템 특성
		- Layer 1: 직접 이웃 (1-hop) 정보
		- Layer 2: 2차 이웃 (2-hop) 정보 → 공통 선호를 가진 사용자들
		- Layer 3+: 더 넓은 커뮤니티 정보
	- K개의 LGC를 지난 이후, 각 레이어에서 얻은 임베딩 합쳐서 최종 결과 도출
		- $e_u = \sum_{k=0}^{K}\alpha_k e_u^{(k)}$
		- $e_i = \sum_{k=0}^{K}\alpha_k e_i^{(k)}$
		  (주의: 0번째 Layer도 합쳐줌)
		- $\alpha_k$: LGC 레이어 별 가중치
			- 하이퍼 파라미터, 수동 튜닝 혹은 자동으로 학습
			- 연구진 측에서 균등 가중치로 가하는게 일반적으로 좋은 성능을 낸다고 언급함
			- $\alpha_k = 1/(K+1)$
	- 3가지 이점
		1. Over-smoothing 방지
			- 깊은 레이어일수록 임베딩이 비슷해지는 문제 해결
			  → 초기 레이어 정보를 보존하여 다양성 유지
		2. 다양한 의미 포착
			- 각 레이어의 고유한 의미를 모두 활용 → 더 풍부한 표현력 생성
		3. Self-connection 효과
			- Layer 0 포함으로 자기 자신의 정보 보존
			  → 별도의 self-connection 불필요
3. Model Prediction
	- 그냥 너무 간단함
	  → 앞서 합친 아이템 및 유저 임베딩 결과 내적하면 끝
	- 최종 예측 결과
		- $\hat{y_{ui}} = e_u^{T}e_{i}$<br><br>

### 실험 결과 요약
- LightGCN vs NGCF
	- NGCF 대비 성능 향상
		- LightGCN은 NGCF에 비해 모든 데이터셋과 레이어 수에서 더 높은 Recall@20, NDCG@20 성능을 보임
		- 4-layer Recall@20
			- NGCF 0.1570 / LightGCN 0.1830
			  (Gowalla 데이터셋)
			- NGCF 0.0344 / LightGCN 0.0406
			  (Amazon-Book 데이터셋)                    
		![image12](../../images/2024-10-29-aitech-week11-12_7_1/image12.png)
	- Layer 수에 따른 성능 변화
		![image13](../../images/2024-10-29-aitech-week11-12_7_1/image13.png)
		- 레이어(Propagation step)를 늘릴수록 성능이 일정 수준까지는 향상되지만, 3~4개 레이어에서 그 효과가 포화되는 경향
		  (이는 NGCF와 유사)
		- 각 데이터셋에서 Layer = 3에서 가장 좋은 성능을 내는 경우가 많습니다.
		- Layer 수에 따른 성능 변화는 Over-smoothing 문제와 직결되는데, LightGCN은 Layer Combination을 통해 이를 효과적으로 해결
		- 그래프로 비교표현(점선: NGCF, 실선: LightGCN)
		![image14](../../images/2024-10-29-aitech-week11-12_7_1/image14.png)                    
		![image15](../../images/2024-10-29-aitech-week11-12_7_1/image15.png)
- LightGCN vs Other competing method
	- 비교 대상
		- NGCF
		- Mult-VAE: VAE(Variational AutoEncoder) 기반의 아이템 추천
		- GRMF: 그래프 라플라시안 정규화 기반 행렬 분해
		- GRMF-norm: 라플라시안 정규화에 노멀라이즈 적용한 버전 등
	- 결과 요약
		- LightGCN의 SOTA 달성
			- 모든 데이터셋에서 기존 모델 대비 가장 높은 Recall@20 및 NDCG@20을 기록
			- NGCF, Mult-VAE, GRMF 등과 같은 최신·강력한 베이스라인들을 일관되게 압도
		- 단순 모델임에도 탁월한 성능
			- LightGCN 구조는 NGCF, Mult-VAE 등보다 훨씬 단순하지만,
			- 복잡한 변환/활성화 없이도 복잡한 모델보다 높은 성능 달성
			  (논문의 핵심 메시지 반복적으로 강조)
		- 벤치마크 결과 예시(아래 표 참조)
			- Gowalla Test: LightGCN (Recall@20: 0.1830) > NGCF (0.1570) > Mult-VAE, GRMF 등 순
			- Yelp2018, Amazon-Book: LightGCN이 모든 평가지표에서 1위, 그 뒤를 NGCF, Mult-VAE 등이 따름
			![image16](../../images/2024-10-29-aitech-week11-12_7_1/image16.png)
- LightGCN 모델이 갖는 의의
	- 실무적으로 매우 강력: 복잡한 네트워크나 데이터 상황에서도, ==튜닝 없이 기본 세팅==으로 SOTA 퍼포먼스 가능
	- 연구적 의의: GCN 기반 추천의 병목요소(불필요한 변환, 오버피팅 요소) 제거의 근거와 실험 결과 제공
	- 확장성/범용성: 미니멀리즘 구조로 대규모 그래프에서도 계산 효율/실용성이 매우 높음<br><br>



