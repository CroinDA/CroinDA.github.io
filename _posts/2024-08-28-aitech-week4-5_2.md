---
layout: single
title: 생성모델
categories:
  - ml_recsys
tags:
  - 부스트캠프
  - AITech
  - AIBasic
  - recsys
  - 통계
  - 확률분포
  - 중심극한정리
  - MLE
  - Likelihood
author_profile: false
use_math: true
---
## 1. 생성모델 개요
### 1.1 생성모델 개요
- Training data가 sampling 된 분포에서 같은 분포의 새로운 sample을 생성하는 model
1. By Formula
	- $P_{\text{data}}(x) \approx P_{\text{model}}(x)$
	- $P_{\text{data}}(x, y) \approx P_{\text{model}}(x, y)$
		- x : text, image, weighted matrix 등
		- y : label
		- 목적: 데이터의 분포를 알고 싶음  → 그것이 어렵기 때문에 <mark style="background: #FFF3A3A6;">우리만의 model을 만들어 데이터 분포에 근사</mark>하여 파악하고자 하는 것
2. By graph
	- Captures <mark style="background: #FFF3A3A6;">a hidden or underlying structure</mark> of the data
		- 아래 그림에서 회색 분포의 추론을 통해, <mark style="background: #FFF3A3A6;">무지막지한 양의 데이터를 추론</mark>할 수 있도록 하는 것
		![image1](../../images/2024-08-28-aitech-week4-5_2/image1.png)
		- 아래 검은색 십자부분: Data ⇒ <mark style="background: #FFF3A3A6;">검은색 십자부분이 생성된 회색분포를 추론</mark>하는 것이 생성모델의 목표
		- Density Estimation
		- Sample Generation
			![image2](../../images/2024-08-28-aitech-week4-5_2/image2.png)
			- x 자체가 어떤 분포에서 나왔을지 추론
			- 레이블(y)도 같이 추론
			- 활용
			    1. CV : 이미지 스타일 변경 / 객체 추가 또는 제거 / 이미지 화질 선명히 복원
			    2. NLP : Text augmentation 제한 시, 생성모델로 새로운 Text 생성 ⇒ 학습 Data 생성
3. 생성모델의 패러독스
	- 생성모델이 만든 답에 대해, 생성모델이 다른 답을 내놓음
		- 마치, $A=B$라 해놓고 같은 질문을 다시 물었을 때 $A \neq B$라고 답하는 격
		- 생성모델은 생성은 잘하지만 이해를 못함 → 계속 발전 중


## 2. 그래피컬 모델 개요
### 2.1 개요
- 생성 모델을 이해하기 위한 그래피컬 모델 
- GMM(Gausian Mixture Models)
	![image2](../../images/2024-08-28-aitech-week4-5_2/image3.png)
	- 각 클러스터에 대한 비중 모델링
	- ex)
	    - Cluster 1 = 0.3
	    - Cluster 2 = 0.5
	    - Cluster 3 = 0.2
	- GMM 표현
		1. 수식
		    - $p(x) = \sum_{i=1}^{K} \pi_i \, N(x \mid \mu_i, \sigma_i)$ - "가우시안 분포가 K개"
			    - $K$ = 클러스터 갯수 
			    - $\pi_i$ = 분포에 대한 비율
			    - $N(x \mid \mu_i, \sigma_i)$ = 가우시안 분포
		2. 그림(plate denote)
			![image3](../../images/2024-08-28-aitech-week4-5_2/image4.png)
			- 우측 K($\mu_k$, $\sum_k$)
				- 분포 별 mean, covariance 하나씩. 
			- 좌측 N
			    1. $\pi$
				    - 매 가우시안 분포 별 비중 (하나만 존재)
			    2. $z_n$
				    - 임의의 cluster sampling
			    3. $x_n$
				    - cluster 내 값 sampling
		3. Generative process
		    - For each data,
		        1. First, choose
		            - $z_n$ ~ $Multinominal(\pi)$ - Cluster Sampling
		        2. Next, choose
		            - $x_n$~ $Gaussian(\mu_{z_n}\sum_{z_n}$) - 클러스터 별 mean, cov 하나씩 → 이에 대응하는 값 Sampling<br><br>

## 3. Variational AutoEncoders(VAE)
### 3.1  VAE 개요
- AutoEncoder
	- 목적 - Input을 넣어서 다시 output으로 복원
		- $||x-x\prime||^2$ 을 최소화 하는 것이 목표
	- Input을 넣어 Output을 그대로 복원하는 목적
		- RecSys에 활용
		- <mark style="background: #FFF3A3A6;">차원축소 알고리즘</mark>으로 활용
			- Hidden Layer로 차원 축소 시, <u>중요 정보만 남기고 불필요한 정보는 날림</u>
			- 실제 공간보다 관찰대상을 잘 설명할 수 있는 latent space를 알아낼 수 있음
			  → 이러한 latent space를 알아내는 것이 차원 축소
		- 해당 신경망이 압축하는 방식을 배우기 위해 → <mark style="background: #FFF3A3A6;">비선형적인 차원감소</mark> 수행
	![image4](images/2024-08-28-aitech-week4-5_2/image5.png)
	![image5](images/2024-08-28-aitech-week4-5_2/image6.png)
	- 구조
		1. Encoder
			- 
	- 차원 축소 알고리즘 - MNIST 데이터 예시
		- 28x28 = 784차원
		- 모든 픽셀은 0 or 1 (검 or 흰)
		- 파라미터의 갯수는 $2^{784}$ → 비효율 연산
		- MNIST 데이터셋은 0-9까지의 숫자를 손글씨로 작성한 이미지 데이터셋 → 크게 10가지로 분류 가능
		- AutoEncoder의 차원 축소 알고리즘을 통해 $2^{784}$ → 10차원으로 <mark style="background: #FFF3A3A6;">중요정보만 남기고</mark> 차원 축소 to Hidden Layer<br><br>

- VAE : Input Image X를 잘 설명하는 feature를 추출하여 latent vector로 embedding하고, 이를 통해 <mark style="background: #FFF3A3A6;">X와 유사하면서 동시에 새로운 데이터를 생성</mark>해 내는 것이 목표
	- 각 feature는 가우시안 분포 따름
	- Latent Vector(Latent Variable)는 각 feature의 평균과 분산을 나타냄
	- AE는 Decoder를 통해 입력 데이터가 출력되듯, VAE는 latent vector를 통해 이미지를 생성해냄

- Hidden Layer - 차원축소 Algorithm으로 많이 활용
    
    ⇒ input에 고차원 데이터 들어올 시, 압축용   
    

- Encoder: “고차원의 input data → 저차원의 hidden layer data”로 압축시켜 표현 가능
    
    ex) 그림당 28x28픽셀(=784차원)의 MNIST Data → 2차원으로 압축 가능 (아래 그림, 표현 벡터)
    
    ![image6](images/2024-08-28-aitech-week4-5_2/image7.png)
    
    → 위 그림과 같이 표현 벡터가 표시되어 있는 벡터 공간: **latent space(잠재공간)**
    
    → 작은 차원으로 줄였기 때문에, 마음껏 시각화 가능
    
    → Class 별로 잘 분류됨 (=Data에 내재된 feature를 잘 학습했다는 의미)
    
    (유사 Data는 같은 것으로 분류)
    

- Decoder: “latent space의 hidden layer data → 본래 size data”로 복원
    
    → representation vector의 원래 의미를 “압축 해제”하여 원본 사이즈의 데이터 형태로 복원
    

![image7](images/2024-08-28-aitech-week4-5_2/image8.png)

- latent space에서 random sampling(검은점)

![image8](images/2024-08-28-aitech-week4-5_2/image9.png)

- Sampling data의 decoder 복원 결과

- Compactness
    ![image9](images/2024-08-28-aitech-week4-5_2/image10.png)
    

### Variational AutoEncoder

- AutoEncoder의 세 가지 한계점
    1. AE는 지금껏 보지 못한 데이터 생성 시 퀄리티 떨어짐
        
        ( = latent space가 빈 공간일 때 생성된 데이터들은 품질이 떨어짐)
        
    2. 인코딩 시, 표현 벡터들의 위치를 선택하는 규칙이 없음 ⇒ 디코딩 시, 매번 인코더가 어떤 좌표에 데이터들을 옮겨 담았는지 **매번 Sampling** 해야하는 번거로움
    3. 어떤 class의 데이터들은 매우 작은 영역에 밀집, 어떤 class의 데이터들은 넓은 지역에 퍼져있음

- 보완책
    
    1번 한계점 → Gaussian 분포 이용 
    
    (목적: 벡터 공간 상의 정확한 위치가 아닌, 살짝 벗어난 곳에 점을 찍을 수 있도록 하여 랜덤성 부여)
    
    2번 한계점 → KL divergence
    

![image.png](Day%202%20%E1%84%89%E1%85%A2%E1%86%BC%E1%84%89%E1%85%A5%E1%86%BC%E1%84%86%E1%85%A9%E1%84%83%E1%85%A6%E1%86%AF%205e78244418314ee59b2e63c7b3cba5f9/image%206.png)

- 좌측: encoder, Train Data / 우측: decoder, Test Data

![image.png](Day%202%20%E1%84%89%E1%85%A2%E1%86%BC%E1%84%89%E1%85%A5%E1%86%BC%E1%84%86%E1%85%A9%E1%84%83%E1%85%A6%E1%86%AF%205e78244418314ee59b2e63c7b3cba5f9/image%207.png)

- z를 p(z)와 동일한 확률분포로 바꿔줘야 KL-Divergence 성질 이용 가능

![image.png](Day%202%20%E1%84%89%E1%85%A2%E1%86%BC%E1%84%89%E1%85%A5%E1%86%BC%E1%84%86%E1%85%A9%E1%84%83%E1%85%A6%E1%86%AF%205e78244418314ee59b2e63c7b3cba5f9/image%208.png)

### 3.2  VAE 목적식

![image.png](Day%202%20%E1%84%89%E1%85%A2%E1%86%BC%E1%84%89%E1%85%A5%E1%86%BC%E1%84%86%E1%85%A9%E1%84%83%E1%85%A6%E1%86%AF%205e78244418314ee59b2e63c7b3cba5f9/image%209.png)

⇒ 목적: $KL(q(z|x)||p(z))$ 최소화

- VAE의 목적식
    
    ![image.png](Day%202%20%E1%84%89%E1%85%A2%E1%86%BC%E1%84%89%E1%85%A5%E1%86%BC%E1%84%86%E1%85%A9%E1%84%83%E1%85%A6%E1%86%AF%205e78244418314ee59b2e63c7b3cba5f9/image%2010.png)
    
    1. KL divergence
    2. Reconstruction Loss
    
    ⇒ 자세한 유도 및 적용과정: 필기자료 참조
    

### 3.3 VAE 활용방안

AutoEncoder 기반 → AutoRec

VAE 기반

![image.png](Day%202%20%E1%84%89%E1%85%A2%E1%86%BC%E1%84%89%E1%85%A5%E1%86%BC%E1%84%86%E1%85%A9%E1%84%83%E1%85%A6%E1%86%AF%205e78244418314ee59b2e63c7b3cba5f9/image%2011.png)

- $y$ (Rating Matrix) → $y\prime$ (더 나은 Rating Matrix)
    
    → 관측이 된 rating은 그대로 잘 복원
    
    → 관측이 안된 rating은 맥락 상 자연스러운 값으로 모델링 완료