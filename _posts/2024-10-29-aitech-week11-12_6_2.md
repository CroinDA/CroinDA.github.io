---
layout: single
title: "[RecSys / \b딥러닝을 활용한 추천시스템] AutoEncoder를 활용한 추천시스템 모델 (AutoRec, CDAE)"
categories:
  - recsys_basic
tags:
  - 부스트캠프
  - AITech
  - RecSys
  - Deep_Learning
  - AutoEncoder
  - AutoRec
  - CDAE
author_profile: false
use_math: true
---
## 1. AutoEncoder
- Input data를 출력으로 복원(Reconstruction)하는 Unsupervised 학습 모델
- 차원축소의 알고리즘으로 RecSys에 활용 → 중요한 것만 남기도 중요하지 않은 것은 날리는 비선형적인 차원감소를 수행하는 방식을 학습
- Hidden Layer를 Input Data의 feature representation으로 활용 
	![image1](../../images/2024-10-29-aitech-week11-12_6_2/image1.png)
- Denoising AutoEncoder(DAE)
	- Input data에 인위적으로 random noise나 dropout을 추가하여 학습
	- 이를 통해, 모델은 데이터 중에서도 더 중요한 특징을 더 잘 학습하게 됨
	- noise input을 더 잘 복원할 수 있도록 robust한 모델이 학습되어 전체적 성능 향상
		  (일반화 성능 향상)
		![image2](../../images/2024-10-29-aitech-week11-12_6_2/image2.png)<br><br>

## 2. AutoRec
- CF에 AutoEncoder를 적용하여 Representation은 향상, Complexity는 감소시킨 성과를 보인 모델
- 아이디어
	- 배경
		- CF → 사용자들의 아이템에 대한 선호도 정보를 활용하여 개인화된 추천을 제공하는 기술
			- Netflix Challenge 이후 다양한 CF 모델 제안
		- AutoRec 연구팀 → CV 및 음성인식 분야에서 성공을 거둔 DL 기술인 AE를 적용하고자 함
			- 차용 근거: 기존 신경망 기반 CF 모델들에 비해 AutoEncoder가 <mark style="background: #FFF3A3A6;">Representation 및 Computational 측면에서 장점</mark> 지님
	- 개요
		- Rating Vector를 입출력으로 하여 Reconstruction 과정 수행
			- user 및 item 벡터를 저차원의 latent feature로 나타내 이를 사용해 평점 예측
		- AutoEncoder의 Representation Learning을 item과 user에 각각 적용
			- Encoder가 input vector를 latent space로 압축 → 이 과정에서 사용자나 아이템의 특징을 집약한 latent feature를 자동으로 학습
		- AutoRec vs. MF
			- AutoRec의 latent feature는 기존의 Matrix Factorization(행렬 분해) 방식에서의 임베딩과 유사하지만, AE는 <mark style="background: #FFF3A3A6;">비선형 변환을 통해 더 복잡한 패턴을 학습</mark>할 수 있습니다
			- MF: Linear, low-order interaction을 통한 representation 학습
			- AutoRec: Non-linear activation function 활용 → 더 복잡한 interaction 표현 가능
- 모델
	- Item과 User, 각각에 대해 임베딩을 따로 진행
		 ![image3](../../images/2024-10-29-aitech-week11-12_6_2/image3.png)
		1. 아이템 기반 AutoRec (I-AutoRec, 위 그림): Item에 대한 Rating Vector $r^i$ 입력
		2. 사용자 기반 AutoRec (U-AutoRec): User에 대한 Rating Vector $r^u$ 입력
	- 동작 원리(I-AutoRec 기준)
		1. 부분적으로 관측된 아이템 벡터 r^(i)를 입력으로 받습니다
		2. 인코더를 통해 저차원 잠재 공간으로 투영합니다
		3. 디코더를 통해 원래 차원으로 복원하여 missing rating을 예측합니다
			- Missing rating: 아직 사용자가 평점을 남기지 않은 평점 값(관측되지 않은 평점 값)
			- 복원된 벡터의 각 원소는 “해당 사용자가 이 아이템에 매길 것으로 예상되는 평점” 의미
			- 초기에 입력되는 $r^i$는 대부분 값이 비어있거나(미관측), 일부 값만 실제 평점으로 채워져 있음 → AutoRec을 통과하면서 채워나가는 과정
- 학습
	1. 입력 데이터 준비
		- 평점 행렬(Rating Matrix): <mark style="background: #FFF3A3A6;">사용자-아이템 평점 행렬</mark> 사용 → 대부분의 값은 비어 있음(대략 95%)
		- 아이템 기반 AutoRec의 경우: 각 아이템(예: 영화)에 대해 모든 사용자의 <mark style="background: #FFF3A3A6;">Rating Vector를 입력</mark>으로 사용
	2. 네트워크 구조
		- Encoder: Input vector(부분적으로 관측된 평점)를 저차원 latent space로 압축
		- Decoder: 압축된 latent feature을 다시 원래 차원(사용자 수)으로 복원
		- Bias: 각 층에 바이어스 항이 더해짐
	3. 순전파(Forward Pass)
		- Input Rating Vector가 Encoder를 거쳐 latent vector로 변환, Decoder를 통해 복원
		- Output Vector의 각 값은 해당 사용자가 해당 아이템에 줄 것으로 예상되는 예측 평점
		- $h(r;\theta) = f(W \cdot g(Vr + \mu)+b)$
			- $r$: 기존 rating
			- $V$: Encoder 가중치
			- $\mu$: Encoder의 bias vector
			- $g(\cdot)$: Encoder의 non-linear activation function
			- $W$: Decoder 가중치
			- $f(\cdot)$: Decoder의 output activation function
			- $b$: Decoder의 bias vector
	4. 손실 함수(Loss Function) 계산
		- 목표: 관측된 평점(실제 값)-복원된 평점(예측 값) 간 오차 최소화
		- 손실 함수: 관측된 값에 대해서만 평균 제곱 오차(MSE) 계산
		- $\min_{\theta} \sum_{\mathbf{r} \in S} \Vert \mathbf{r} - h(\mathbf{r}; \theta) \Vert_2^2$
	5. 역전파(Backpropagation) 및 파라미터 업데이트
		- 역전파: 손실 함수의 값을 바탕으로, 신경망의 가중치와 바이어스 파라미터에 대해 그래디언트 계산
		- 관측된 값만 업데이트: 손실과 그래디언트 계산은 <mark style="background: #FFF3A3A6;">실제로 평점이 있는(관측된) 위치에 대해서만 이뤄짐</mark> → 미관측값(비어 있는 값)은 학습에 관여하지 않음
		- 최적화 알고리즘: 일반적으로 Adam, SGD, RProp 등 딥러닝에서 널리 쓰이는 최적화 기법 사용
	6. 반복 학습 (Epoch)
		- 위 과정을 여러 epoch 반복하면서, 네트워크 파라미터가 관측된 평점을 더 잘 복원하도록 계속 업데이트 → missing rating에 대한 예측값의 신뢰도 점점 높아짐
- 모델의 실험 결과 및 의의
	- MovieLens 및 Netflix 데이터셋에서 RBM, MF 보다 좋은 성능
	- Item based vs User based: User based method보다 <mark style="background: #FFF3A3A6;">Item based method가 일반적으로 더 좋은 성능</mark> 보임 → 아이템당 평균 평점 수가 사용자당 평균 평점 수보다 많기 때문
	- 활성화 함수의 중요성: <mark style="background: #FFF3A3A6;">Hidden Layer에서의 비선형성</mark>($g(\cdot)$)이 I-AutoRec의 우수한 성능에영향 → MF에 비헤 장점
	- Hidden Unit 갯수의 영향: Hidden Layer 내 Unit 갯수가 증가할수록 성능은 향상, 수익은 감소 효과
		- 수익 감소 효과: 유닛 수를 계속 늘리면 어느 순간부터는 성능 향상 폭이 점점 줄어듦.
		- 50개에서 100개로 늘릴 때는 성능이 많이 좋아지지만, 400개에서 500개로 늘릴 때는 성능 개선이 미미해짐<br><br>

## 3. CDAE
- AutoRec은 Rating Prediction을 위한 모델 → CDAE는 Ranking을 통해 유저에 Top-N 추천을 제공
- Denoising AE를 CF에 적용한 모델<br><br>
- 아이디어 및 문제 정의
	- 문제 단순화를 위해, User-Item 상호 작용 정보를 binary information으로 바꿔 학습 데이터로 활용
	- 가장 큰 차이 2가지
		1. DAE를 활용하기에, noise 추가
			![image4](../../images/2024-10-29-aitech-week11-12_6_2/image4.png)
			- Dropout masking
				- 입력 벡터 $y_u$의 각 원소 $y_{ud}$를 확률적으로 0으로 바꿔 <mark style="background: #FFF3A3A6;">일부 정보를 의도적으로 누락</mark>
			- $P(\tilde{y}_u = \delta y_u) = 1 - q$
				- 확률로 원래 값을 유지(단, 스케일링 상수  곱함)
			- $P(\tilde{y}_u = 0) = q$
				- $\tilde{y_u}$: $q$의 확률에 의해 0으로 drop-out된 벡터<br><br>
			- $\tilde{y}_u$: 사용자 $u$의 노이즈가 추가된 input vector
				- 원본 벡터 $y_u$: 사용자 $u$가 선호하는 아이템 정보를 담은 벡터(0~1)
			- $q$: Dropout 확률(input 벡터의 각 원소가 0이 될 확률)
			- $\delta$: 스케일링 상수, dropout으로 인해 전체 입력의 평균 크기가 줄어드는 현상 보정을 위해 사용
		2. 유저 파라미터 $V_u$ 학습
			- 개인화: 모든 사용자가 같은 입력 벡터만으로는 개별 취향을 충분히 반영할 수 없음
			- 협업 필터링의 본질: 사용자 간의 행동 패턴을 비교·학습하여, 비슷한 취향의 사용자가 선호한 아이템을 추천하는 것이 핵심
			- $V_u$를 통해
				- 사용자의 고유한 특성을 latent space에 직접 반영
				- 입력이 일부 결손(노이즈)되어도, 보조 역할을 하여 더 정확한 복원이 가능
				- 유저에 따른 특징을 학습하여, Top N 추천에 사용<br><br>
			- Encoder를 통해 생성된 latent representation $z_u$, Decoder로 Regenerate
				- $z_u = h(W^T\tilde{y_u}+V_u+b)$
					- $V_u$: 사용자 별 고유 파라미터 → 유저 별 특징 학습
				- $\hat{y}_{ui} = f\left( {W'_i}^\top z_u + b'_i \right)$
- 결과 → 대체적으로 N값에 관계 없이, 다른 top-N 추천 모델에 비해 더 높은 MAP & Recall값 보임
	![image5](../../images/2024-10-29-aitech-week11-12_6_2/image5.png)